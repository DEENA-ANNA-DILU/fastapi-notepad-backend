"""
LLM integration placeholder.
Model selected: google/flan-t5-small (Hugging Face)
Actual inference can be enabled when environment supports torch.
"""

def summarize_text(text: str) -> str:
    # Placeholder logic (safe for Windows)
    return text[:100]
